{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darrenCWJ/huggingface_rl/blob/main/notebooks/optuna_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Hyperparameter tuning with Optuna\n",
        "\n",
        "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
        "\n",
        "Optuna: https://github.com/optuna/optuna\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hYdv2ygjLaFL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "b200262f-9bdc-4c90-a492-05cdf7b9d5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (1.5.0)\n",
            "Collecting importlib-metadata~=4.13\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting gym==0.21\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 30.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (1.13.0+cu116)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable-baselines3) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable-baselines3) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3) (2022.6)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616825 sha256=d5bf61d847aa9d72bdd4a8aa19cd643453308856345abb90ac1973df14a99d93\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/6d/b3/a3a6e10704795c9b9000f1ab2dc480dfe7bed42f5972806e73\n",
            "Successfully built gym\n",
            "Installing collected packages: importlib-metadata, gym, stable-baselines3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 5.1.0\n",
            "    Uninstalling importlib-metadata-5.1.0:\n",
            "      Successfully uninstalled importlib-metadata-5.1.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "Successfully installed gym-0.21.0 importlib-metadata-4.13.0 stable-baselines3-1.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oexj67yWN5_k",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "bb79bfdd-34d1-4983-f761-b954df0c99f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-1.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: stable-baselines3>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from sb3-contrib) (1.6.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (4.13.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (1.13.0+cu116)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (1.3.5)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (0.21.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable-baselines3>=1.6.2->sb3-contrib) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable-baselines3>=1.6.2->sb3-contrib) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable-baselines3>=1.6.2->sb3-contrib) (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3>=1.6.2->sb3-contrib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3>=1.6.2->sb3-contrib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3>=1.6.2->sb3-contrib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable-baselines3>=1.6.2->sb3-contrib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3>=1.6.2->sb3-contrib) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable-baselines3>=1.6.2->sb3-contrib) (2022.6)\n",
            "Installing collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-1.6.2\n"
          ]
        }
      ],
      "source": [
        "# Optional: install SB3 contrib to have access to additional algorithms\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNah91r9x9EL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "635834af-e36e-438f-e987-8f7c48f31d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.5-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cliff\n",
            "  Downloading cliff-4.1.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.9.1-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 70.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (4.13.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 45.2 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=9a389719a77f81894f161c5aa245cb77bff92b6ba945d68c55851c830c6b5e5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.9.1 autopage-0.5.1 cliff-4.1.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.5 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.1\n"
          ]
        }
      ],
      "source": [
        "# Optuna will be used in the last part when doing hyperparameter tuning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R7tKaBFrTR0a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EcsXmYRMON9W",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Algorithms from the contrib repo\n",
        "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "from sb3_contrib import QRDQN, TQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLwjcfvuqtGE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khNkrgcI6Z1"
      },
      "source": [
        "# Part I: The Importance Of Tuned Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PytOtL9GdmrE"
      },
      "source": [
        "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc. \n",
        "\n",
        "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8HSIC3qUjc"
      },
      "source": [
        "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
        "\n",
        "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
        "\n",
        "\n",
        "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ToIvihGq2N0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "env_id = \"Pendulum-v1\"\n",
        "# Env used only for evaluation\n",
        "eval_envs = make_vec_env(env_id, n_envs=10)\n",
        "# 4000 training timesteps\n",
        "budget_pendulum = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWT2r6QE4yew"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KCHk_-_4ndux",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP9C9AqLndxz",
        "outputId": "d6985a9d-820f-444d-c295-5f0a6e6a1f35",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1180.39 +/- 295.77\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmJaJLl5ds4"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BLL_pws25jh0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Define and train a A2C model\n",
        "a2c_model = A2C(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ic83jZwB5nVk",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "153d65ba-63a9-410b-d196-274ee3f9e505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2C Mean episode reward: -1516.52 +/- 202.25\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the train A2C model\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_z1zFx2rVpG"
      },
      "source": [
        "Both are far from solving the env (mean reward around -200).\n",
        "Now, let's try with an off-policy algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYaVZJU5VL5"
      },
      "source": [
        "### Training longer PPO ?\n",
        "\n",
        "Maybe training longer would help?\n",
        "\n",
        "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hHsHpnQY6TWA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# train longer\n",
        "new_budget = 10 * budget_pendulum\n",
        "\n",
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7OD9y1o36Xta",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "ce73e0a9-b85b-41a3-fd58-a6cb1f39c4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1179.76 +/- 324.59\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvQ9SJ15Xmh"
      },
      "source": [
        "### PPO - Tuned Hyperparameters\n",
        "\n",
        "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "S-D_vvsb6jOZ",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "713183dd-21ac-449c-98ed-89eefcf55519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'Pendulum-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -1.21e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 752        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 13         |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02073822 |\n",
            "|    clip_fraction        | 0.177      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.69      |\n",
            "|    explained_variance   | 0.826      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 12.7       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0143    |\n",
            "|    std                  | 0.939      |\n",
            "|    value_loss           | 38.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -1.05e+03  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 717        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 28         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03141796 |\n",
            "|    clip_fraction        | 0.224      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.3       |\n",
            "|    explained_variance   | 0.967      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 3.12       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0317    |\n",
            "|    std                  | 0.518      |\n",
            "|    value_loss           | 10.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -676        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 709         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019762024 |\n",
            "|    clip_fraction        | 0.286       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.38        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    std                  | 0.324       |\n",
            "|    value_loss           | 3.3         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -360        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 706         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 58          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024678972 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.988       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.27        |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 0.279       |\n",
            "|    value_loss           | 2.44        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 200       |\n",
            "|    ep_rew_mean          | -243      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 704       |\n",
            "|    iterations           | 25        |\n",
            "|    time_elapsed         | 72        |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0357166 |\n",
            "|    clip_fraction        | 0.205     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.26     |\n",
            "|    explained_variance   | 0.998     |\n",
            "|    learning_rate        | 0.001     |\n",
            "|    loss                 | 0.123     |\n",
            "|    n_updates            | 240       |\n",
            "|    policy_gradient_loss | -0.0173   |\n",
            "|    std                  | 0.221     |\n",
            "|    value_loss           | 0.389     |\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tuned_params = {\n",
        "    \"gamma\": 0.9,\n",
        "    \"use_sde\": True,\n",
        "    \"sde_sample_freq\": 4,\n",
        "    \"learning_rate\": 1e-3,\n",
        "}\n",
        "\n",
        "# budget = 10 * budget_pendulum\n",
        "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuxoLxt67xO",
        "outputId": "796bfb6f-8c9c-4529-f266-5f1b060a904b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned PPO Mean episode reward: -174.14 +/- 117.81\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H33u_apWPp5"
      },
      "source": [
        "Note: if you try SAC on the simple MountainCarContinuous environment, you will encounter some issues without tuned hyperparameters: https://github.com/rail-berkeley/softlearning/issues/76\n",
        "\n",
        "Simple environments can be challenging even for SOTA algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdpPJ04nebx"
      },
      "source": [
        "# Part II: Grad Student Descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PNN9kcgolk"
      },
      "source": [
        "### Challenge (10 minutes): \"Grad Student Descent\" \n",
        "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
        "\n",
        "\n",
        "Maximum reward: 500 on `CartPole-v1`\n",
        "\n",
        "The hyperparameters should work for different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "s6aqxsini7H3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "budget = 20_000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ805DBi3KM"
      },
      "source": [
        "#### The baseline: default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pyOCKf4Vt-HK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D1PSNGcsi2dP",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "678df605-0d94-4dbb-c170-6b0d573890ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.9     |\n",
            "|    ep_rew_mean        | 10.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.325   |\n",
            "|    explained_variance | 0.495    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.311    |\n",
            "|    value_loss         | 4.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.8     |\n",
            "|    ep_rew_mean        | 10.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 677      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.201   |\n",
            "|    explained_variance | 0.934    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0195  |\n",
            "|    value_loss         | 0.194    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.8     |\n",
            "|    ep_rew_mean        | 12.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 680      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.22     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.39     |\n",
            "|    value_loss         | 4.92     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.5     |\n",
            "|    ep_rew_mean        | 15.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 681      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0.00158  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.79     |\n",
            "|    value_loss         | 7.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 18.8     |\n",
            "|    ep_rew_mean        | 18.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 678      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.677   |\n",
            "|    explained_variance | -0.0782  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.24     |\n",
            "|    value_loss         | 6.24     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.5     |\n",
            "|    ep_rew_mean        | 22.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 683      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.544   |\n",
            "|    explained_variance | 0.00921  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.4      |\n",
            "|    value_loss         | 5.73     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.7     |\n",
            "|    ep_rew_mean        | 25.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 683      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.664   |\n",
            "|    explained_variance | -0.00296 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.1      |\n",
            "|    value_loss         | 5.09     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.7     |\n",
            "|    ep_rew_mean        | 30.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 684      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.625   |\n",
            "|    explained_variance | -0.0546  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.11     |\n",
            "|    value_loss         | 4.45     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.6     |\n",
            "|    ep_rew_mean        | 34.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 684      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | 0.000963 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.15     |\n",
            "|    value_loss         | 3.9      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.4     |\n",
            "|    ep_rew_mean        | 38.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | 0.00127  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.954    |\n",
            "|    value_loss         | 3.37     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.5     |\n",
            "|    ep_rew_mean        | 44.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 686      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.583   |\n",
            "|    explained_variance | 0.00281  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 1.01     |\n",
            "|    value_loss         | 2.9      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.1      |\n",
            "|    ep_rew_mean        | 49.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 688       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.61     |\n",
            "|    explained_variance | -0.000986 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 0.785     |\n",
            "|    value_loss         | 2.44      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 52.7     |\n",
            "|    ep_rew_mean        | 52.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 690      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.556   |\n",
            "|    explained_variance | -0.00225 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.434    |\n",
            "|    value_loss         | 2.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 57.9     |\n",
            "|    ep_rew_mean        | 57.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.548   |\n",
            "|    explained_variance | 0.000206 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.432    |\n",
            "|    value_loss         | 1.64     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 62.1     |\n",
            "|    ep_rew_mean        | 62.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.569   |\n",
            "|    explained_variance | 1.32e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.539    |\n",
            "|    value_loss         | 1.31     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 66.1     |\n",
            "|    ep_rew_mean        | 66.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.463   |\n",
            "|    explained_variance | 0.000127 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.328    |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 70.5     |\n",
            "|    ep_rew_mean        | 70.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.564   |\n",
            "|    explained_variance | 6.14e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.239    |\n",
            "|    value_loss         | 0.761    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 75.1     |\n",
            "|    ep_rew_mean        | 75.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.624   |\n",
            "|    explained_variance | 0.000281 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.249    |\n",
            "|    value_loss         | 0.532    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 79.3     |\n",
            "|    ep_rew_mean        | 79.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.539   |\n",
            "|    explained_variance | 1.69e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.221    |\n",
            "|    value_loss         | 0.351    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 83       |\n",
            "|    ep_rew_mean        | 83       |\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.401   |\n",
            "|    explained_variance | 5.63e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.207    |\n",
            "|    value_loss         | 0.207    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 87.5     |\n",
            "|    ep_rew_mean        | 87.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.315   |\n",
            "|    explained_variance | 0.000259 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.244    |\n",
            "|    value_loss         | 0.0992   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 91.7     |\n",
            "|    ep_rew_mean        | 91.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.547   |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0704   |\n",
            "|    value_loss         | 0.0296   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 96.3      |\n",
            "|    ep_rew_mean        | 96.3      |\n",
            "| time/                 |           |\n",
            "|    fps                | 693       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.221    |\n",
            "|    explained_variance | -0.000129 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 0.0556    |\n",
            "|    value_loss         | 0.00158   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 99.4     |\n",
            "|    ep_rew_mean        | 99.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.509   |\n",
            "|    explained_variance | 0.0037   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0011   |\n",
            "|    value_loss         | 7.47e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 104      |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.51    |\n",
            "|    explained_variance | 7.88e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.000215 |\n",
            "|    value_loss         | 1e-06    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 110      |\n",
            "|    ep_rew_mean        | 110      |\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.416   |\n",
            "|    explained_variance | 0.00754  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00159  |\n",
            "|    value_loss         | 2.94e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 113      |\n",
            "|    ep_rew_mean        | 113      |\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.528   |\n",
            "|    explained_variance | 0.00922  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.000397 |\n",
            "|    value_loss         | 1.19e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 117      |\n",
            "|    ep_rew_mean        | 117      |\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.481   |\n",
            "|    explained_variance | 0.000593 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 5.19e-05 |\n",
            "|    value_loss         | 2.24e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.591   |\n",
            "|    explained_variance | -2.97    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 4.1e-05  |\n",
            "|    value_loss         | 1.69e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 126      |\n",
            "|    ep_rew_mean        | 126      |\n",
            "| time/                 |          |\n",
            "|    fps                | 695      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.414   |\n",
            "|    explained_variance | 0.08     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 9.43e-06 |\n",
            "|    value_loss         | 8.61e-10 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 131       |\n",
            "|    ep_rew_mean        | 131       |\n",
            "| time/                 |           |\n",
            "|    fps                | 695       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.541    |\n",
            "|    explained_variance | -1.57     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -1.95e-06 |\n",
            "|    value_loss         | 2.68e-10  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 136       |\n",
            "|    ep_rew_mean        | 136       |\n",
            "| time/                 |           |\n",
            "|    fps                | 695       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.526    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | -6.36e-06 |\n",
            "|    value_loss         | 2.44e-10  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 140      |\n",
            "|    ep_rew_mean        | 140      |\n",
            "| time/                 |          |\n",
            "|    fps                | 694      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.421   |\n",
            "|    explained_variance | -2.43    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 1.48e-05 |\n",
            "|    value_loss         | 4.13e-09 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 145       |\n",
            "|    ep_rew_mean        | 145       |\n",
            "| time/                 |           |\n",
            "|    fps                | 694       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.547    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -8.36e-07 |\n",
            "|    value_loss         | 1.16e-11  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 149      |\n",
            "|    ep_rew_mean        | 149      |\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.357   |\n",
            "|    explained_variance | 9.48e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.000944 |\n",
            "|    value_loss         | 1.37e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 154      |\n",
            "|    ep_rew_mean        | 154      |\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 25       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.286   |\n",
            "|    explained_variance | -0.0706  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000655 |\n",
            "|    value_loss         | 3.99e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 159      |\n",
            "|    ep_rew_mean        | 159      |\n",
            "| time/                 |          |\n",
            "|    fps                | 693      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | 0.00626  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.000157 |\n",
            "|    value_loss         | 2.58e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 163      |\n",
            "|    ep_rew_mean        | 163      |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.501   |\n",
            "|    explained_variance | 0.111    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 0.000114 |\n",
            "|    value_loss         | 1.22e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 168      |\n",
            "|    ep_rew_mean        | 168      |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.465   |\n",
            "|    explained_variance | 0.000632 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 0.00019  |\n",
            "|    value_loss         | 3.3e-07  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 171      |\n",
            "|    ep_rew_mean        | 171      |\n",
            "| time/                 |          |\n",
            "|    fps                | 692      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | -0.15    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.000228 |\n",
            "|    value_loss         | 1.9e-07  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3X0G0ng2OE",
        "outputId": "3f42354a-9a43-44b3-a381-d3ae63be6782",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fi1-oKnUI2"
      },
      "source": [
        "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvq8zizok1X_"
      },
      "source": [
        "Time to tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UaqCCH4gkRH_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uDUfeZcyjPKS",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "47ba85cb-5c22-49c3-a168-bed714d4e5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.9     |\n",
            "|    ep_rew_mean        | 10.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 655      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 0        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.325   |\n",
            "|    explained_variance | 0.495    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.311    |\n",
            "|    value_loss         | 4.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 10.8     |\n",
            "|    ep_rew_mean        | 10.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 651      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.201   |\n",
            "|    explained_variance | 0.934    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -0.0195  |\n",
            "|    value_loss         | 0.194    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 12.8     |\n",
            "|    ep_rew_mean        | 12.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 658      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.22     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.39     |\n",
            "|    value_loss         | 4.92     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 15.5     |\n",
            "|    ep_rew_mean        | 15.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 660      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.676   |\n",
            "|    explained_variance | 0.00158  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.79     |\n",
            "|    value_loss         | 7.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 18.8     |\n",
            "|    ep_rew_mean        | 18.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.677   |\n",
            "|    explained_variance | -0.0782  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 1.24     |\n",
            "|    value_loss         | 6.24     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.5     |\n",
            "|    ep_rew_mean        | 22.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 4        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.544   |\n",
            "|    explained_variance | 0.00921  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.4      |\n",
            "|    value_loss         | 5.73     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.7     |\n",
            "|    ep_rew_mean        | 25.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 662      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.664   |\n",
            "|    explained_variance | -0.00296 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.1      |\n",
            "|    value_loss         | 5.09     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.7     |\n",
            "|    ep_rew_mean        | 30.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 663      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.625   |\n",
            "|    explained_variance | -0.0546  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.11     |\n",
            "|    value_loss         | 4.45     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.6     |\n",
            "|    ep_rew_mean        | 34.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 663      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | 0.000963 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.15     |\n",
            "|    value_loss         | 3.9      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 38.4     |\n",
            "|    ep_rew_mean        | 38.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | 0.00127  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.954    |\n",
            "|    value_loss         | 3.37     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 44.5     |\n",
            "|    ep_rew_mean        | 44.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 665      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.583   |\n",
            "|    explained_variance | 0.00281  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 1.01     |\n",
            "|    value_loss         | 2.9      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.1      |\n",
            "|    ep_rew_mean        | 49.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 666       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.61     |\n",
            "|    explained_variance | -0.000986 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 0.785     |\n",
            "|    value_loss         | 2.44      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 52.7     |\n",
            "|    ep_rew_mean        | 52.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.556   |\n",
            "|    explained_variance | -0.00225 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.434    |\n",
            "|    value_loss         | 2.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 57.9     |\n",
            "|    ep_rew_mean        | 57.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.548   |\n",
            "|    explained_variance | 0.000206 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.432    |\n",
            "|    value_loss         | 1.64     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 62.1     |\n",
            "|    ep_rew_mean        | 62.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 7500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.569   |\n",
            "|    explained_variance | 1.32e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | 0.539    |\n",
            "|    value_loss         | 1.31     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 66.1     |\n",
            "|    ep_rew_mean        | 66.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.463   |\n",
            "|    explained_variance | 0.000127 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.328    |\n",
            "|    value_loss         | 1.02     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 70.5     |\n",
            "|    ep_rew_mean        | 70.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.564   |\n",
            "|    explained_variance | 6.14e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.239    |\n",
            "|    value_loss         | 0.761    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 75.1     |\n",
            "|    ep_rew_mean        | 75.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 9000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.624   |\n",
            "|    explained_variance | 0.000281 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | 0.249    |\n",
            "|    value_loss         | 0.532    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 79.3     |\n",
            "|    ep_rew_mean        | 79.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.539   |\n",
            "|    explained_variance | 1.69e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.221    |\n",
            "|    value_loss         | 0.351    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 83       |\n",
            "|    ep_rew_mean        | 83       |\n",
            "| time/                 |          |\n",
            "|    fps                | 669      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.401   |\n",
            "|    explained_variance | 5.63e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 0.207    |\n",
            "|    value_loss         | 0.207    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 87.5     |\n",
            "|    ep_rew_mean        | 87.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 10500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.315   |\n",
            "|    explained_variance | 0.000259 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.244    |\n",
            "|    value_loss         | 0.0992   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 91.7     |\n",
            "|    ep_rew_mean        | 91.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 668      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.547   |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.0704   |\n",
            "|    value_loss         | 0.0296   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 96.3      |\n",
            "|    ep_rew_mean        | 96.3      |\n",
            "| time/                 |           |\n",
            "|    fps                | 667       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.221    |\n",
            "|    explained_variance | -0.000129 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 0.0556    |\n",
            "|    value_loss         | 0.00158   |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 99.4     |\n",
            "|    ep_rew_mean        | 99.4     |\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.509   |\n",
            "|    explained_variance | 0.0037   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0011   |\n",
            "|    value_loss         | 7.47e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 104      |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 667      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.51    |\n",
            "|    explained_variance | 7.88e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.000215 |\n",
            "|    value_loss         | 1e-06    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 110      |\n",
            "|    ep_rew_mean        | 110      |\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.416   |\n",
            "|    explained_variance | 0.00754  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00159  |\n",
            "|    value_loss         | 2.94e-05 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 113      |\n",
            "|    ep_rew_mean        | 113      |\n",
            "| time/                 |          |\n",
            "|    fps                | 665      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.528   |\n",
            "|    explained_variance | 0.00922  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.000397 |\n",
            "|    value_loss         | 1.19e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 117      |\n",
            "|    ep_rew_mean        | 117      |\n",
            "| time/                 |          |\n",
            "|    fps                | 665      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.481   |\n",
            "|    explained_variance | 0.000593 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 5.19e-05 |\n",
            "|    value_loss         | 2.24e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.591   |\n",
            "|    explained_variance | -2.97    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 4.1e-05  |\n",
            "|    value_loss         | 1.69e-08 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 126      |\n",
            "|    ep_rew_mean        | 126      |\n",
            "| time/                 |          |\n",
            "|    fps                | 664      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.414   |\n",
            "|    explained_variance | 0.08     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 9.43e-06 |\n",
            "|    value_loss         | 8.61e-10 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 131       |\n",
            "|    ep_rew_mean        | 131       |\n",
            "| time/                 |           |\n",
            "|    fps                | 663       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.541    |\n",
            "|    explained_variance | -1.57     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -1.95e-06 |\n",
            "|    value_loss         | 2.68e-10  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 136       |\n",
            "|    ep_rew_mean        | 136       |\n",
            "| time/                 |           |\n",
            "|    fps                | 663       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.526    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | -6.36e-06 |\n",
            "|    value_loss         | 2.44e-10  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 140      |\n",
            "|    ep_rew_mean        | 140      |\n",
            "| time/                 |          |\n",
            "|    fps                | 662      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.421   |\n",
            "|    explained_variance | -2.43    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 1.48e-05 |\n",
            "|    value_loss         | 4.13e-09 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 145       |\n",
            "|    ep_rew_mean        | 145       |\n",
            "| time/                 |           |\n",
            "|    fps                | 661       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.547    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | -8.36e-07 |\n",
            "|    value_loss         | 1.16e-11  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 149      |\n",
            "|    ep_rew_mean        | 149      |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.357   |\n",
            "|    explained_variance | 9.48e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 0.000944 |\n",
            "|    value_loss         | 1.37e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 154      |\n",
            "|    ep_rew_mean        | 154      |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.286   |\n",
            "|    explained_variance | -0.0706  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000655 |\n",
            "|    value_loss         | 3.99e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 159      |\n",
            "|    ep_rew_mean        | 159      |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | 0.00626  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | 0.000157 |\n",
            "|    value_loss         | 2.58e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 163      |\n",
            "|    ep_rew_mean        | 163      |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.501   |\n",
            "|    explained_variance | 0.111    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | 0.000114 |\n",
            "|    value_loss         | 1.22e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 168      |\n",
            "|    ep_rew_mean        | 168      |\n",
            "| time/                 |          |\n",
            "|    fps                | 661      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 29       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.465   |\n",
            "|    explained_variance | 0.000632 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 0.00019  |\n",
            "|    value_loss         | 3.3e-07  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 171      |\n",
            "|    ep_rew_mean        | 171      |\n",
            "| time/                 |          |\n",
            "|    fps                | 660      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | -0.15    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.000228 |\n",
            "|    value_loss         | 1.9e-07  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch=[\n",
        "      dict(vf=[64, 64], pi=[64, 64]), # network architectures for actor/critic\n",
        "    ],\n",
        "    activation_fn=nn.Tanh,\n",
        ")\n",
        "\n",
        "hyperparams = dict(\n",
        "    n_steps=5, # number of steps to collect data before updating policy\n",
        "    learning_rate=7e-4,\n",
        "    gamma=0.99, # discount factor\n",
        "    max_grad_norm=0.5, # The maximum value for the gradient clipping\n",
        "    ent_coef=0.0, # Entropy coefficient for the loss calculation\n",
        ")\n",
        "\n",
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "br80i2yqIyVC",
        "outputId": "54ec10f4-050a-47e6-c962-aabb3af846f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:500.00 +/- 0.00\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL_G9DurUV75"
      },
      "source": [
        "Hint - Recommended Hyperparameter Range\n",
        "\n",
        "```python\n",
        "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
        "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "# from 2**3 = 8 to 2**10 = 1024\n",
        "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
        "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "# activation_fn = nn.Tanh / nn.ReLU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFOp0j-ga-_"
      },
      "source": [
        "# Part III: Automatic Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x7wMyyud5p"
      },
      "source": [
        "In this part we will create a script that allows to search for the best hyperparameters automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwR-30IvHeY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VM6tUr-yuekR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVfmM1dzA1d"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yyBTVcAGzCRk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(2e4)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25HgcDYzvJ0b"
      },
      "source": [
        "### Exercise (5 minutes): Define the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KXo8AwGAvN8Q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # - define the learning rate search space [1e-5, 1] (log) -> `suggest_float`\n",
        "    # - define the network architecture search space [\"tiny\", \"small\"] -> `suggest_categorical`\n",
        "    # - define the activation function search space [\"tanh\", \"relu\"]\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1, log=True)\n",
        "    net_arch = trial.suggest_categorical('net_arch',[\"tiny\", \"small\"])\n",
        "    activation_fn = trial.suggest_categorical('activation_fn',[\"tanh\", \"relu\"])\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybymNiJxNu7"
      },
      "source": [
        "### Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY8Z8tuxai7"
      },
      "source": [
        "First we define a custom callback to report the results of periodic evaluations to Optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "U5ijWTPzxSmd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "    \n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cHNM_cFO3vs"
      },
      "source": [
        "### Exercise (10 minutes): Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76voi9AXxlCq"
      },
      "source": [
        "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "E0yEokTDxhrC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    \"\"\"\n",
        "    Objective function using by Optuna to evaluate\n",
        "    one configuration (i.e., one set of hyperparameters).\n",
        "\n",
        "    Given a trial object, it will sample hyperparameters,\n",
        "    evaluate it and report the result (mean episodic reward after training)\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: Mean episodic reward after training\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO: \n",
        "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
        "    # 2. Create the evaluation envs\n",
        "    # 3. Create the `TrialEvalCallback`\n",
        "\n",
        "    # 1. Sample hyperparameters and update the keyword arguments\n",
        "    kwargs.update(sample_a2c_params(trial))\n",
        "    # Create the RL model\n",
        "    model = A2C(**kwargs)\n",
        "\n",
        "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
        "    eval_env = make_vec_env(ENV_ID,N_EVAL_ENVS)\n",
        "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
        "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
        "    # TrialEvalCallback signature:\n",
        "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
        "    eval_callback = TrialEvalCallback(eval_env,trial, N_EVAL_EPISODES, EVAL_FREQ, deterministic= True, verbose=0)\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFLu_M0ymzj"
      },
      "source": [
        "### The optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4UU17YpjymPr",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "69edd86b-c620-4e7c-ff08-ef1a7e77e258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-12-28 15:01:16,936]\u001b[0m A new study created in memory with name: no-name-4836fd97-8375-4b63-8422-2b1adc16d678\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:01:34,275]\u001b[0m Trial 0 finished with value: 500.0 and parameters: {'gamma': 0.0006007163746112048, 'max_grad_norm': 2.3076507631580787, 'exponent_n_steps': 7, 'learning_rate': 0.0008878617905080161, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:01:46,506]\u001b[0m Trial 1 finished with value: 9.3 and parameters: {'gamma': 0.000298383977303828, 'max_grad_norm': 0.6123989194453477, 'exponent_n_steps': 9, 'learning_rate': 0.2788810689789373, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:02:10,799]\u001b[0m Trial 2 finished with value: 9.4 and parameters: {'gamma': 0.0007667621040070687, 'max_grad_norm': 1.9783062347845675, 'exponent_n_steps': 3, 'learning_rate': 0.03810166564575148, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:02:25,061]\u001b[0m Trial 3 finished with value: 9.4 and parameters: {'gamma': 0.012487177480793664, 'max_grad_norm': 1.7208980301701113, 'exponent_n_steps': 10, 'learning_rate': 0.08000315402049768, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:02:41,004]\u001b[0m Trial 4 finished with value: 103.1 and parameters: {'gamma': 0.0025397978113794414, 'max_grad_norm': 2.8772680524256207, 'exponent_n_steps': 4, 'learning_rate': 2.8805098562806035e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:02:56,003]\u001b[0m Trial 5 finished with value: 157.9 and parameters: {'gamma': 0.0001106493214751447, 'max_grad_norm': 4.342933840279739, 'exponent_n_steps': 7, 'learning_rate': 0.00017234339046368492, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:03:12,114]\u001b[0m Trial 6 finished with value: 500.0 and parameters: {'gamma': 0.08988977780834391, 'max_grad_norm': 0.8814925627392637, 'exponent_n_steps': 6, 'learning_rate': 0.001330424339845786, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:03:28,698]\u001b[0m Trial 7 finished with value: 500.0 and parameters: {'gamma': 0.0027669116606983415, 'max_grad_norm': 1.147552426656299, 'exponent_n_steps': 7, 'learning_rate': 0.002129533291203782, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:03:35,937]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:03:43,066]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:03:49,997]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:06,292]\u001b[0m Trial 11 finished with value: 500.0 and parameters: {'gamma': 0.05038072436744158, 'max_grad_norm': 0.8807031440275622, 'exponent_n_steps': 6, 'learning_rate': 0.0013764367987315616, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:23,040]\u001b[0m Trial 12 finished with value: 483.6 and parameters: {'gamma': 0.08038681357832632, 'max_grad_norm': 0.5859225523793845, 'exponent_n_steps': 6, 'learning_rate': 0.0005003687360689836, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:30,845]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:39,204]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:46,758]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:04:54,207]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:06,146]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:12,620]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:19,864]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:29,178]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:44,742]\u001b[0m Trial 21 finished with value: 500.0 and parameters: {'gamma': 0.0029909644965681517, 'max_grad_norm': 0.9327294819003075, 'exponent_n_steps': 7, 'learning_rate': 0.0030771613319076556, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:05:52,075]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:07,325]\u001b[0m Trial 23 finished with value: 500.0 and parameters: {'gamma': 0.0024581667505170087, 'max_grad_norm': 1.0041680102434658, 'exponent_n_steps': 8, 'learning_rate': 0.0032688106571506195, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:15,020]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:22,046]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:28,241]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:35,926]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:53,233]\u001b[0m Trial 28 finished with value: 472.5 and parameters: {'gamma': 0.08972369580525777, 'max_grad_norm': 1.5627571743314164, 'exponent_n_steps': 5, 'learning_rate': 0.001652559070591448, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:06:59,543]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:07:07,558]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:07:14,835]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:07:22,302]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:07:38,839]\u001b[0m Trial 33 finished with value: 500.0 and parameters: {'gamma': 0.045515420845730334, 'max_grad_norm': 0.7963592722956453, 'exponent_n_steps': 6, 'learning_rate': 0.001667366284092807, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:07:46,091]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:01,269]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:10,611]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:17,799]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:23,652]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:31,304]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:39,975]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:08:56,581]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:09:12,765]\u001b[0m Trial 42 finished with value: 500.0 and parameters: {'gamma': 0.05072272434464407, 'max_grad_norm': 0.8263332569765499, 'exponent_n_steps': 6, 'learning_rate': 0.0017675434842817112, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:09:28,318]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:09:43,893]\u001b[0m Trial 44 finished with value: 117.6 and parameters: {'gamma': 0.043552972785652525, 'max_grad_norm': 0.5162876764176472, 'exponent_n_steps': 6, 'learning_rate': 0.008428512290152958, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:09:51,125]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:07,058]\u001b[0m Trial 46 finished with value: 230.6 and parameters: {'gamma': 0.030205159615793606, 'max_grad_norm': 0.8453324991981563, 'exponent_n_steps': 6, 'learning_rate': 0.005590497459472195, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:14,483]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:22,771]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:32,238]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:39,235]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:10:46,993]\u001b[0m Trial 51 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:02,905]\u001b[0m Trial 52 finished with value: 197.5 and parameters: {'gamma': 0.000907421765383836, 'max_grad_norm': 0.3413886859918941, 'exponent_n_steps': 6, 'learning_rate': 0.0012399641377316356, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:10,352]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:18,231]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:26,201]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:39,736]\u001b[0m Trial 56 finished with value: 500.0 and parameters: {'gamma': 0.002484406997749465, 'max_grad_norm': 2.530623063116492, 'exponent_n_steps': 7, 'learning_rate': 0.006598730959588068, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:11:55,187]\u001b[0m Trial 57 finished with value: 500.0 and parameters: {'gamma': 0.015446038150886935, 'max_grad_norm': 1.0153681867983944, 'exponent_n_steps': 8, 'learning_rate': 0.003985332093396899, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:12:01,514]\u001b[0m Trial 58 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:12:16,809]\u001b[0m Trial 59 finished with value: 311.8 and parameters: {'gamma': 0.01395338485815809, 'max_grad_norm': 0.979297215167437, 'exponent_n_steps': 9, 'learning_rate': 0.0035767597795744676, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:12:30,614]\u001b[0m Trial 60 finished with value: 500.0 and parameters: {'gamma': 0.03214149081163625, 'max_grad_norm': 2.8857124656843682, 'exponent_n_steps': 6, 'learning_rate': 0.0064940854134157835, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:12:43,953]\u001b[0m Trial 61 finished with value: 500.0 and parameters: {'gamma': 0.002971348778136182, 'max_grad_norm': 3.3152497320942294, 'exponent_n_steps': 8, 'learning_rate': 0.009452472255042895, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:12:50,440]\u001b[0m Trial 62 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:03,774]\u001b[0m Trial 63 finished with value: 500.0 and parameters: {'gamma': 0.004885670416441399, 'max_grad_norm': 3.5656687437816137, 'exponent_n_steps': 8, 'learning_rate': 0.009520890946544371, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:10,302]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:27,371]\u001b[0m Trial 65 finished with value: 196.0 and parameters: {'gamma': 0.05815809272556811, 'max_grad_norm': 0.8368537362836217, 'exponent_n_steps': 5, 'learning_rate': 0.00364054978625444, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:34,901]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:41,199]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:47,432]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:13:55,086]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:02,453]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:18,954]\u001b[0m Trial 71 finished with value: 500.0 and parameters: {'gamma': 0.0027595382360565864, 'max_grad_norm': 1.1806394655280288, 'exponent_n_steps': 7, 'learning_rate': 0.004648892020541708, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:25,623]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:32,339]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:38,536]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:45,675]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:52,229]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:14:59,302]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:07,201]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:14,531]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:28,498]\u001b[0m Trial 80 finished with value: 500.0 and parameters: {'gamma': 0.0002468189984335044, 'max_grad_norm': 3.3138115296396506, 'exponent_n_steps': 6, 'learning_rate': 0.008009556605521427, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:42,390]\u001b[0m Trial 81 finished with value: 500.0 and parameters: {'gamma': 0.041928152032579394, 'max_grad_norm': 3.6938757442198518, 'exponent_n_steps': 6, 'learning_rate': 0.009891465759054786, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:48,962]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:15:55,549]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:16:02,187]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:16:08,904]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:16:15,996]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-12-28 15:16:31,170]\u001b[0m Trial 87 finished with value: 500.0 and parameters: {'gamma': 0.07137589850970176, 'max_grad_norm': 3.5572927432523023, 'exponent_n_steps': 5, 'learning_rate': 0.0014199020149463656, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: 500.0.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials:  88\n",
            "Best trial:\n",
            "  Value: 500.0\n",
            "  Params: \n",
            "    gamma: 0.0006007163746112048\n",
            "    max_grad_norm: 2.3076507631580787\n",
            "    exponent_n_steps: 7\n",
            "    learning_rate: 0.0008878617905080161\n",
            "    net_arch: small\n",
            "    activation_fn: tanh\n",
            "  User attrs:\n",
            "    gamma_: 0.9993992836253888\n",
            "    n_steps: 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"bd257187-d1af-4e12-a6ec-5cda457c2c15\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bd257187-d1af-4e12-a6ec-5cda457c2c15\")) {                    Plotly.newPlot(                        \"bd257187-d1af-4e12-a6ec-5cda457c2c15\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,11,12,21,23,28,33,42,44,46,52,56,57,59,60,61,63,65,71,80,81,87],\"y\":[500.0,9.3,9.4,9.4,103.1,157.9,500.0,500.0,500.0,483.6,500.0,500.0,472.5,500.0,500.0,117.6,230.6,197.5,500.0,500.0,311.8,500.0,500.0,500.0,196.0,500.0,500.0,500.0,500.0],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,11,12,21,23,28,33,42,44,46,52,56,57,59,60,61,63,65,71,80,81,87],\"y\":[500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0,500.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bd257187-d1af-4e12-a6ec-5cda457c2c15');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b541c609-441b-4d9b-8f85-a9226b5a37f9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b541c609-441b-4d9b-8f85-a9226b5a37f9\")) {                    Plotly.newPlot(                        \"b541c609-441b-4d9b-8f85-a9226b5a37f9\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"gamma (FloatDistribution): 0.011165856716889622<extra></extra>\",\"net_arch (CategoricalDistribution): 0.015204370178518343<extra></extra>\",\"activation_fn (CategoricalDistribution): 0.017154973299508804<extra></extra>\",\"max_grad_norm (FloatDistribution): 0.08520539726848417<extra></extra>\",\"exponent_n_steps (IntDistribution): 0.22582690074314396<extra></extra>\",\"learning_rate (FloatDistribution): 0.6454425017934551<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.01\",\"0.02\",\"0.02\",\"0.09\",\"0.23\",\"0.65\"],\"textposition\":\"outside\",\"x\":[0.011165856716889622,0.015204370178518343,0.017154973299508804,0.08520539726848417,0.22582690074314396,0.6454425017934551],\"y\":[\"gamma\",\"net_arch\",\"activation_fn\",\"max_grad_norm\",\"exponent_n_steps\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b541c609-441b-4d9b-8f85-a9226b5a37f9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCbep6z1h3D1"
      },
      "source": [
        "Complete example: https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUeYnfJVpB2"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- the importance of good hyperparameters\n",
        "- how to do automatic hyperparameter search with optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-gqIPXqV7zZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "icra22_optuna_lab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}